import re
import requests
import logging
import json
import time
from bs4 import BeautifulSoup
from openai import OpenAI
from tenacity import retry, stop_after_attempt, wait_exponential, wait_fixed

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ÙˆØ¬Ø± Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„ØªØªØ¨Ø¹ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - [ğŸ›¡ï¸ WEBAI-AUTO-HEALER] - %(levelname)s - %(message)s'
)
logger = logging.getLogger("WebAI_Healer")

class AdvancedContentValidator:
    def __init__(self, openai_client, model_name="gemini"):
        """
        openai_client: Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØµÙ„ Ø¨Ø³ÙŠØ±ÙØ± WebAI Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ.
        model_name: Ø§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ gemini Ù„Ø£Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± ÙŠØ­ÙˆÙ„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø¥Ù„ÙŠÙ‡).
        """
        self.client = openai_client
        self.model_name = model_name

    def _normalize(self, text):
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© Ù„Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©"""
        return re.sub(r'\s+', ' ', text.strip().lower())

    # ==============================================================================
    # 1. STRUCTURAL HEALING (Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ù„Ù„Ù…Ù‚Ø§Ù„)
    # ==============================================================================
    def ensure_structure_integrity(self, html_content, full_source_text):
        """
        ÙŠÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠØ© (Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©ØŒ ÙˆØµÙ†Ø¯ÙˆÙ‚ Ø§Ù„Ø£Ø¯ÙˆØ§Øª).
        Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ ÙŠØ·Ù„Ø¨ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¦Ù‡Ø§ Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±.
        """
        logger.info("ğŸ› ï¸ Checking structural integrity...")
        soup = BeautifulSoup(html_content, 'html.parser')
        modified = False

        # ØªØ­Ø¯ÙŠØ¯ Ù†Ù‚Ø·Ø© Ø§Ù„Ø­Ù‚Ù† (Ø¨Ø¹Ø¯ Ø£ÙˆÙ„ Ø¹Ù†ÙˆØ§Ù† H2 Ø£Ùˆ Ø£ÙˆÙ„ ÙÙ‚Ø±Ø©)
        injection_point = soup.find('h2') or soup.find('p')

        # 1. ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        if "comparison-table" not in html_content:
            logger.warning("âš ï¸ Comparison Table is missing! Generating now...")
            table_html = self._generate_element_via_ai("Comparison Table", full_source_text)
            if table_html and "<table" in table_html:
                new_tag = BeautifulSoup(table_html, 'html.parser')
                if injection_point:
                    injection_point.insert_after(new_tag)
                    modified = True
                    logger.info("âœ… Fixed: Comparison Table injected.")

        # 2. ÙØ­Øµ ÙˆØ¬ÙˆØ¯ ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø§Ù„Ø«Ù‚Ø© (Authority Widgets)
        widgets = ['code-snippet', 'specs-box', 'roi-box', 'pros-cons-grid']
        if not any(w in html_content for w in widgets):
            logger.warning("âš ï¸ Authority Widget is missing! Generating now...")
            # Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„ØµÙ†Ø¯ÙˆÙ‚ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù†Øµ
            widget_type = "Pros & Cons Grid"
            if "code" in full_source_text.lower() or "python" in full_source_text.lower():
                widget_type = "Code Snippet"
            elif "specs" in full_source_text.lower() or "battery" in full_source_text.lower():
                widget_type = "Specs Box"

            widget_html = self._generate_element_via_ai(widget_type, full_source_text)
            if widget_html:
                new_tag = BeautifulSoup(widget_html, 'html.parser')
                # Ù†Ø­Ù‚Ù†Ù‡ Ø¨Ø¹Ø¯ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø£Ùˆ Ø¨Ø¹Ø¯ Ù†Ù‚Ø·Ø© Ø§Ù„Ø­Ù‚Ù† Ø§Ù„Ø£ÙˆÙ„Ù‰
                if injection_point:
                    injection_point.insert_after(new_tag)
                    modified = True
                    logger.info(f"âœ… Fixed: {widget_type} injected.")

        return str(soup) if modified else html_content

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(5))
    def _generate_element_via_ai(self, element_type, source_text):
        """Ø·Ù„Ø¨ Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆÙ„ÙŠØ¯ Ø¹Ù†ØµØ± Ù…Ø­Ø¯Ø¯ ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ø³ÙŠØ±ÙØ±"""
        prompt = f"""
        TASK: Generate a missing HTML element for a tech blog.
        ELEMENT TO GENERATE: {element_type}
        SOURCE DATA: {source_text[:6000]}
        
        STRICT HTML RULES:
        - Use ONLY these classes: 'table-wrapper', 'comparison-table', 'code-snippet', 'specs-box', 'pros-cons-grid'.
        - For tables, every <td> MUST have a 'data-label' attribute.
        - Return ONLY the HTML code. No talk.
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}]
            )
            return response.choices[0].message.content.replace("```html", "").replace("```", "").strip()
        except Exception as e:
            logger.error(f"âŒ Failed to generate {element_type}: {e}")
            return ""

    # ==============================================================================
    # 2. FACT HEALING (Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø±Ù‚Ù…ÙŠ ÙˆØ§Ù„Ø­Ù‚Ø§Ø¦Ù‚)
    # ==============================================================================
    def verify_and_heal_facts(self, html_content, source_text):
        """
        ÙŠØ³ØªØ®Ø±Ø¬ Ø§Ù„ÙÙ‚Ø±Ø§Øª Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… (Ø³Ø¹Ø§Øª Ø¨Ø·Ø§Ø±ÙŠØ©ØŒ Ø£Ø³Ø¹Ø§Ø±ØŒ Ù†Ø³Ø¨)
        ÙˆÙŠÙ‚Ø§Ø±Ù†Ù‡Ø§ Ø¨Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„ØªØµØ­ÙŠØ­ Ø£ÙŠ "Ù‡Ù„ÙˆØ³Ø©".
        """
        logger.info("ğŸ” Fact-checking numbers and claims...")
        soup = BeautifulSoup(html_content, 'html.parser')
        paragraphs = soup.find_all(['p', 'li'])
        
        suspicious_nodes = []
        # Regex Ù„Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø¨Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
        num_regex = r'\b(?!(?:202[0-9]|2030)\b)\d+(?:\.\d+)?'

        for node in paragraphs:
            if re.search(num_regex, node.get_text()):
                suspicious_nodes.append(str(node))

        if not suspicious_nodes:
            return html_content

        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ÙÙ‚Ø±Ø§Øª Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø© Ù„Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ø¬Ù…Ø§Ø¹ÙŠ (Batch Fact Check)
        correction_map = self._ai_batch_fact_check(suspicious_nodes, source_text)
        
        final_html = str(soup)
        fixed_count = 0
        for original, corrected in correction_map.items():
            if original != corrected and original in final_html:
                final_html = final_html.replace(original, corrected)
                fixed_count += 1
        
        if fixed_count > 0:
            logger.info(f"âœ… Healed {fixed_count} factual errors.")
        return final_html

    def _ai_batch_fact_check(self, nodes_html, source_text):
        """Ø·Ù„Ø¨ Ù‚Ø§Ù…ÙˆØ³ ØªØµØ­ÙŠØ­Ø§Øª Ù…Ù† Ø§Ù„Ø³ÙŠØ±ÙØ± Ø¨ØµÙŠØºØ© JSON"""
        prompt = f"""
        TASK: Fact-Check HTML snippets against Source Truth.
        SOURCE TRUTH: {source_text[:12000]}
        INPUT SNIPPETS: {json.dumps(nodes_html)}
        
        INSTRUCTIONS:
        1. Compare numbers/claims in snippets with Source Truth.
        2. If a number is wrong, fix it. If a claim is hallucinated, rewrite it to be safe.
        3. Return a JSON object where KEY is the original snippet and VALUE is the corrected snippet.
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}],
                response_format={"type": "json_object"}
            )
            return json.loads(response.choices[0].message.content)
        except Exception as e:
            logger.error(f"âŒ Fact Check AI error: {e}")
            return {}

    # ==============================================================================
    # 3. QUOTE HEALING (Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª Ø§Ù„Ù…Ø²ÙŠÙØ©)
    # ==============================================================================
    def verify_and_swap_quotes(self, html_content, source_text):
        """
        ÙŠÙØ­Øµ Ø§Ù„Ù€ blockquotes. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ Ù†ØµÙŠØ§Ù‹ ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø±ØŒ
        ÙŠØªÙ… Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ø§Ù‚ØªØ¨Ø§Ø³ Ø­Ù‚ÙŠÙ‚ÙŠ (Verbatim) Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø±.
        """
        logger.info("ğŸ’¬ Verifying quotes...")
        soup = BeautifulSoup(html_content, 'html.parser')
        quotes = soup.find_all('blockquote')
        
        for bq in quotes:
            text = bq.get_text().lower()
            # ÙØ­Øµ: Ù‡Ù„ 4 ÙƒÙ„Ù…Ø§Øª Ù…ØªØªØ§Ù„ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø±ØŸ
            words = text.split()
            found_real = False
            if len(words) > 5:
                for i in range(len(words)-4):
                    chunk = " ".join(words[i:i+4])
                    if chunk in source_text.lower():
                        found_real = True
                        break
            
            if not found_real:
                logger.warning("âš ï¸ Fake quote detected! Swapping with a real one...")
                real_quote_html = self._get_real_quote_from_ai(source_text)
                if real_quote_html:
                    bq.replace_with(BeautifulSoup(real_quote_html, 'html.parser'))
                    logger.info("âœ… Fixed: Fake quote replaced.")
                else:
                    bq.decompose() # Ø­Ø°ÙÙ‡ ØªÙ…Ø§Ù…Ø§Ù‹ Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø¨Ø¯ÙŠÙ„Ø§Ù‹ Ø­Ù‚ÙŠÙ‚ÙŠØ§Ù‹

        return str(soup)

    def _get_real_quote_from_ai(self, source_text):
        prompt = f"Extract ONE exact verbatim quote from this text: {source_text[:8000]}. Format: <blockquote>Quote</blockquote><footer>Source</footer>. If no quote found, return 'NONE'."
        try:
            resp = self.client.chat.completions.create(
                model=self.model_name,
                messages=[{"role": "user", "content": prompt}]
            )
            content = resp.choices[0].message.content
            return None if "NONE" in content else content
        except: return None

    # ==============================================================================
    # 4. LINK HEALING (Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ÙƒØ³ÙˆØ±Ø©)
    # ==============================================================================
    def heal_broken_links(self, html_content, sources_list):
        """
        ÙŠØªØ­Ù‚Ù‚ Ù…Ù† ÙƒÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø¹Ø·Ù„Ø§Ù‹ (404)ØŒ
        ÙŠØ³ØªØ¨Ø¯Ù„Ù‡ Ø¨Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù…Ù‚Ø§Ù„ Ù„Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø±ÙˆØ§Ø¨Ø· Ù…ÙŠØªØ©.
        """
        logger.info("ğŸ”— Checking for broken links...")
        soup = BeautifulSoup(html_content, 'html.parser')
        links = soup.find_all('a', href=True)
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}

        fixed_links = 0
        for link in links:
            url = link['href']
            if "blogger.com" in url or "#" in url: continue
            
            try:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø³Ø±ÙŠØ¹Ø© Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
                res = requests.head(url, headers=headers, timeout=5, allow_redirects=True)
                if res.status_code >= 400:
                    raise Exception("Broken")
            except:
                logger.warning(f"âš ï¸ Broken link found: {url}. Healing...")
                # Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ø£ÙˆÙ„ Ø±Ø§Ø¨Ø· Ù…ØµØ¯Ø± Ù…ØªØ§Ø­
                if sources_list:
                    link['href'] = sources_list[0]['url']
                    fixed_links += 1
        
        if fixed_links > 0:
            logger.info(f"âœ… Healed {fixed_links} broken links.")
        return str(soup)

    # ==============================================================================
    # MASTER RUNNER (Ø§Ù„Ù…Ø´ØºÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ù…Ø¯Ù‚Ù‚)
    # ==============================================================================
    def run_professional_validation(self, html_content, full_source_text, sources_list_metadata):
        """
        Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙŠ ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¤Ù‡ Ù…Ù† Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ.
        """
        logger.info("ğŸ›¡ï¸ STARTING WEBAI PROFESSIONAL SELF-HEALING PROTOCOL...")
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ù‡ÙŠÙƒÙ„ (Ø¬Ø¯Ø§ÙˆÙ„ØŒ ØµÙ†Ø§Ø¯ÙŠÙ‚)
        html = self.ensure_structure_integrity(html_content, full_source_text)
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: ØªØµØ­ÙŠØ­ Ø§Ù„Ø­Ù‚Ø§Ø¦Ù‚ ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù…
        html = self.verify_and_heal_facts(html, full_source_text)
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³Ø§Øª
        html = self.verify_and_swap_quotes(html, full_source_text)
        
        # Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        html = self.heal_broken_links(html, sources_list_metadata)
        
        logger.info("âœ… SELF-HEALING PROTOCOL COMPLETE.")
        return html
